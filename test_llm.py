# ============ å…¬å¸ç¯å¢ƒï¼šå¼ºåˆ¶å…¨å±€ç¦ç”¨ SSL éªŒè¯ï¼ˆå¿…é¡»åœ¨å…¶ä»–å¯¼å…¥ä¹‹å‰ï¼‰ ============
import os
import ssl

os.environ["PYTHONHTTPSVERIFY"] = "0"
os.environ["CURL_CA_BUNDLE"] = ""
os.environ["REQUESTS_CA_BUNDLE"] = ""
os.environ["SSL_CERT_FILE"] = ""
os.environ["SSL_CERT_DIR"] = ""

try:
    _unverified_context = ssl.create_default_context()
    _unverified_context.check_hostname = False
    _unverified_context.verify_mode = ssl.CERT_NONE
    ssl._create_default_https_context = lambda: _unverified_context
except Exception:
    pass

# ============ æ­£å¸¸å¯¼å…¥ ============
import json
import sys
from pathlib import Path

import httpx
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = os.getenv("DEEPAGENTS_CONFIG", "./config.json")
    path = Path(config_path)
    if not path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return {}
    
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        return data if isinstance(data, dict) else {}
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
        return {}


def apply_env(config):
    """åº”ç”¨ç¯å¢ƒå˜é‡"""
    env = config.get("env")
    if isinstance(env, dict):
        for key, value in env.items():
            if key and value is not None and key not in os.environ:
                os.environ[str(key)] = str(value)


def test_llm():
    """æµ‹è¯• LLM è¿æ¥"""
    print("=" * 50)
    print("ğŸ”§ LLM è¿æ¥æµ‹è¯•è„šæœ¬")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config = load_config()
    apply_env(config)
    
    model_config = config.get("model", {})
    model_name = model_config.get("name", "gpt-5")
    
    # å»æ‰å¯èƒ½çš„ openai: å‰ç¼€
    if model_name.startswith("openai:"):
        model_name = model_name.split(":", 1)[1]
    
    api_key = os.environ.get("OPENAI_API_KEY", "")
    base_url = os.environ.get("OPENAI_BASE_URL", "")
    
    print(f"\nğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   æ¨¡å‹: {model_name}")
    print(f"   API Base: {base_url or '(é»˜è®¤ OpenAI)'}")
    print(f"   API Key: {'***' + api_key[-4:] if len(api_key) > 4 else '(æœªè®¾ç½®)'}")
    
    # å‡†å¤‡ headers
    default_headers = {"apikey": api_key} if base_url else {}
    accesscode = model_config.get("accesscode") or model_config.get("authorization") or os.environ.get("ACCESSCODE", "")
    if accesscode:
        default_headers["Authorization"] = accesscode
        print(f"   AccessCode: ***{accesscode[-4:] if len(accesscode) > 4 else '(å·²è®¾ç½®)'}")
    
    print(f"\nğŸš€ æ­£åœ¨æµ‹è¯•è¿æ¥...")
    
    try:
        # åˆ›å»º LLM
        http_client = httpx.Client(verify=False)
        http_async_client = httpx.AsyncClient(verify=False)
        
        llm_kwargs = {
            "model": model_name,
            "api_key": api_key,
            "http_client": http_client,
            "http_async_client": http_async_client,
            "max_retries": 0,
        }
        
        if base_url:
            llm_kwargs["base_url"] = base_url
            llm_kwargs["default_headers"] = default_headers
        
        llm = ChatOpenAI(**llm_kwargs)
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        test_message = "è¯·ç”¨ä¸€å¥è¯å›å¤ï¼šä½ å¥½"
        print(f"\nğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯: \"{test_message}\"")
        
        response = llm.invoke([HumanMessage(content=test_message)])
        
        print(f"\nâœ… è¿æ¥æˆåŠŸ!")
        print(f"ğŸ“¥ æ¨¡å‹å›å¤: {response.content}")
        print("\n" + "=" * 50)
        return True
        
    except Exception as e:
        print(f"\nâŒ è¿æ¥å¤±è´¥!")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"   é”™è¯¯ä¿¡æ¯: {e}")
        print("\nğŸ’¡ æ’æŸ¥å»ºè®®:")
        print("   1. æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®")
        print("   2. æ£€æŸ¥ OPENAI_BASE_URL æ˜¯å¦å¯è®¿é—®")
        print("   3. æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®")
        print("   4. å¦‚éœ€ accesscodeï¼Œè¯·åœ¨ config.json çš„ model.accesscode ä¸­é…ç½®")
        print("\n" + "=" * 50)
        return False


if __name__ == "__main__":
    success = test_llm()
    sys.exit(0 if success else 1)
